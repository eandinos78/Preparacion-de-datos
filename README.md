üìä Preparaci√≥n y Preprocesamiento de Datos

El preprocesamiento de datos es una etapa fundamental en cualquier proyecto de an√°lisis o ciencia de datos. Su objetivo es mejorar la calidad de los datos antes de aplicar t√©cnicas estad√≠sticas o modelos de aprendizaje autom√°tico.

üîπ Etapas del Preprocesamiento
El flujo general aplicado en este proyecto sigue la siguiente secuencia:

Cleaning ‚Üí Formatting ‚Üí Normalization ‚Üí Encoding

1. Cleaning (Limpieza de datos)
Consiste en identificar y corregir problemas en los datos originales, tales como:

Eliminaci√≥n de valores nulos o vac√≠os.

Eliminaci√≥n de registros duplicados.

Correcci√≥n de errores o inconsistencias.

Eliminaci√≥n de datos irrelevantes para el an√°lisis.

2. Formatting (Formateo de datos)
Se enfoca en estandarizar la estructura y el tipo de los datos:

Conversi√≥n de tipos de datos (fechas, n√∫meros, texto).

Estandarizaci√≥n de formatos (fechas, unidades de medida).

Separaci√≥n o combinaci√≥n de campos de texto cuando es necesario.

3. Normalization (Normalizaci√≥n de datos)
Proceso de escalamiento de variables num√©ricas para mantener proporciones adecuadas entre los valores:

Normalizaci√≥n en rango [0,1].

Estandarizaci√≥n con media 0 y desviaci√≥n est√°ndar 1.

Este paso es clave para algoritmos sensibles a la magnitud de los datos.

4. Encoding (Codificaci√≥n de variables categ√≥ricas)
Transformaci√≥n de variables categ√≥ricas en valores num√©ricos:

Codificaci√≥n binaria (ejemplo: F ‚Üí 0, M ‚Üí 1).

One-Hot Encoding para variables con m√∫ltiples categor√≠as.


üßπ Limpieza de Valores Faltantes

üî∏ Identificaci√≥n de valores faltantes
Los valores faltantes pueden presentarse como:

NaN

Campos en blanco

Valores nulos

üî∏ Estrategias para tratar valores faltantes
Antes de tomar una decisi√≥n, se recomienda:

Verificar la fuente de recolecci√≥n de datos.

Evaluar si es posible recuperar el valor faltante con el recolector de datos.

Las estrategias aplicables incluyen:

‚úîÔ∏è Eliminaci√≥n de valores faltantes

Eliminar la variable: cuando el porcentaje de valores faltantes es muy alto.

Eliminar registros: cuando el n√∫mero de filas afectadas es reducido.

‚úîÔ∏è Reemplazo de valores faltantes

Reemplazo por el promedio (para variables num√©ricas).

Reemplazo por la moda o valor m√°s frecuente (para variables categ√≥ricas).

Reemplazo basado en criterios del dominio, apoyado en la experiencia del recolector o experto.

‚úîÔ∏è Conservaci√≥n de valores faltantes

En algunos casos, los valores faltantes se conservan si aportan informaci√≥n relevante o si el modelo puede manejarlos directamente.


# Informacion general de los datos 

-Nombre de las columnas 

df.columnas

- Tama√±o del conjunto de datos

df.shape

-Tipos de los datos de cada variable 

df.dtypes

-Estad√≠stica b√°sica 

df. describe() #Solo num√©rico 

df.describe(include="all") #Incluye todos 


- Resumen t√©cnico del df

df.info()


-Deterninar los valores faltantes

print(df.isnull().sum())


# Limpieza 

-Limpieza de valores faltantes

import numpy as np

df = df.replace("?", np.nan)


# Visualizacion de Datos 

- Jornada

- Conteo 

conteo_jornada = df["Jornada_ Estudio"].value_counts()
conteo_jornada


calificacion = df["Nota_Estimada_Parcial"].value_counts()
calificacion

-Tabla de relacion jornada y Calificacion

tabla = pd.crosstab(
    df["Jornada_ Estudio"],
    df["Nota_Estimada_Parcial"],
    normalize="index"
) * 100

tabla

- Grafica de relacion jornada y Calificacion

import matplotlib.pyplot as plt
import pandas as pd

# Tabla cruzada
tabla = pd.crosstab(df["Jornada_ Estudio"], df["Nota_Estimada_Parcial"])
tabla = tabla[calificacion.index]

# Convertir a porcentaje por jornada (por fila)
tabla_pct = tabla.div(tabla.sum(axis=1), axis=0) * 100

# Gr√°fico
ax = tabla_pct.plot(
    kind="bar",
    stacked=True,
    figsize=(10,6)
)

ax.set_title("Distribuci√≥n porcentual de la Nota Estimada Parcial por Jornada")
ax.set_xlabel("Jornada")
ax.set_ylabel("Porcentaje (%)")

# Etiquetas de porcentaje
for container in ax.containers:
    ax.bar_label(
        container,
        fmt="%.1f%%",
        label_type="center",
        fontsize=9
    )

plt.legend(title="Rango de nota", bbox_to_anchor=(1.02, 1), loc="upper left")
plt.tight_layout()
plt.show()

- Analisis estadistico

-CDM
py -m pip install scipy

-nottebook
from scipy.stats import chi2_contingency

tabla = pd.crosstab(
    df["Jornada_ Estudio"],
    df["Nota_Estimada_Parcial"]
)

chi2, p_valor, dof, esperados = chi2_contingency(tabla)

print("Chi-cuadrado:", round(chi2, 3))
print("p-valor:", p_valor)


- Grup By

- Primero

import numpy as np
import pandas as pd

mapa = {
    "Entre 0 y 20": 10,
    "Entre 21 y 40": 30.5,
    "Entre 41 y 64": 52.5,
    "Entre 65 y 80": 72.5,
    "Entre 81 y 100": 90.5
}

df["Nota_Numerica"] = df["Nota_Estimada_Parcial"].map(mapa)


df.groupby("Jornada_ Estudio")["Nota_Numerica"].mean().sort_values(ascending=False)


- Segundo

df.groupby("Jornada_ Estudio")["Nota_Numerica"].agg(["count","mean","median","std"])


- Cluster

py -m pip install scikit-learn

from sklearn.cluster import KMeans

X = df[["Nota_Numerica"]].dropna()

kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
df.loc[X.index, "cluster"] = kmeans.fit_predict(X)

df.groupby("cluster")["Nota_Numerica"].agg(["count","mean","min","max"])



  
